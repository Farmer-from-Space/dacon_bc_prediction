{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5da4ad",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3371e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06eee164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1 True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')  if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "\n",
    "torch.manual_seed(787)\n",
    "if device == 'cpu':\n",
    "    torch.manual_seed(787)\n",
    "    \n",
    "print(torch.__version__, torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97dfd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/krc/Documents/breast_dacon/open\n"
     ]
    }
   ],
   "source": [
    "# 경로 지정\n",
    "import pandas as pd\n",
    "\n",
    "train_path = '/Users/krc/Documents/breast_dacon/open/train_small'\n",
    "test_path = '/Users/krc/Documents/breast_dacon/open/test_imgs'\n",
    "%cd /Users/krc/Documents/breast_dacon/open\n",
    "# Dataset_path = '/content/drive/MyDrive/파이토치/solo_project'\n",
    "\n",
    "# based on table - \n",
    "train_df = pd.read_csv('./train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3abf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df, train_labels, test_labels = train_test_split(\n",
    "                                                    train_df.drop(columns=['N_category']),\n",
    "                                                    train_df['N_category'], \n",
    "                                                    test_size=0.1,  # 0.2 \n",
    "                                                    random_state=787\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0e1a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/krc/Documents/breast_dacon/open'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6e4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "# import tensorflow as tf # 얜 왜.. ? \n",
    "\n",
    "class inhovation_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, labels, transform=None):\n",
    "        self.df = df\n",
    "        self.labels = labels.tolist()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist() # 이거 왜 list .. ?\n",
    "            print( index, type(index))\n",
    "        data_path = f\"./train_small/{self.df['img_path'].iloc[index][13:]}\"\n",
    "        image = cv2.imread(data_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #transform \n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image = image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        # label\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image # for test dataset\n",
    "    def __len__(self):\n",
    "        length = len(self.df)\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4df0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "# !pip install Pillow==8.2.0\n",
    "import albumentations.pytorch\n",
    "\n",
    "albumentations_train = albumentations.Compose([\n",
    "\n",
    "    albumentations.Resize(512, 512),\n",
    "    albumentations.OneOf([\n",
    "                            albumentations.HorizontalFlip(p=0.5),\n",
    "                            # albumentations.RandomRotate90(p=0.8),\n",
    "                            albumentations.VerticalFlip(p=0.5)\n",
    "        \n",
    "    ], p=1),\n",
    "    albumentations.OneOf([\n",
    "                            albumentations.MotionBlur(p=0.5),\n",
    "                            albumentations.OpticalDistortion(p=0.5),\n",
    "                            albumentations.GaussNoise(p=0.5)\n",
    "        \n",
    "        \n",
    "    ], p=1),\n",
    "    albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()\n",
    "    ])\n",
    "\n",
    "albumentations_test = albumentations.Compose([\n",
    "    \n",
    "    albumentations.Resize(512, 512),\n",
    "    albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()\n",
    "    \n",
    "])\n",
    "\n",
    "trainset = inhovation_Dataset(train_df, labels=train_labels, transform = albumentations_train)\n",
    "testset = inhovation_Dataset(test_df, labels=test_labels,transform = albumentations_train)\n",
    "\n",
    "albumentations_train_loader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                                         shuffle = True, num_workers=0)\n",
    "albumentations_test_loader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                                        shuffle = False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80406ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca255309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krc/miniforge3/envs/pytorch/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import resnet\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "resnet50 = models.resnet50(weights=True).to(device)\n",
    "\n",
    "resnet50.fc\n",
    "#resnet50.fc = nn.Linear(resnet50.fc.in_fearues, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daf1dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.Sigmoid(),\n",
    "        ) # this part can be finetuned\n",
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1ef92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
      "            Conv2d-5         [-1, 64, 128, 128]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
      "              ReLU-7         [-1, 64, 128, 128]               0\n",
      "            Conv2d-8         [-1, 64, 128, 128]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
      "             ReLU-10         [-1, 64, 128, 128]               0\n",
      "           Conv2d-11        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 128, 128]             512\n",
      "           Conv2d-13        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 128, 128]             512\n",
      "             ReLU-15        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-16        [-1, 256, 128, 128]               0\n",
      "           Conv2d-17         [-1, 64, 128, 128]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 128, 128]             128\n",
      "             ReLU-19         [-1, 64, 128, 128]               0\n",
      "           Conv2d-20         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 128, 128]             128\n",
      "             ReLU-22         [-1, 64, 128, 128]               0\n",
      "           Conv2d-23        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 128, 128]             512\n",
      "             ReLU-25        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-26        [-1, 256, 128, 128]               0\n",
      "           Conv2d-27         [-1, 64, 128, 128]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 128, 128]             128\n",
      "             ReLU-29         [-1, 64, 128, 128]               0\n",
      "           Conv2d-30         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 128, 128]             128\n",
      "             ReLU-32         [-1, 64, 128, 128]               0\n",
      "           Conv2d-33        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 128, 128]             512\n",
      "             ReLU-35        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-36        [-1, 256, 128, 128]               0\n",
      "           Conv2d-37        [-1, 128, 128, 128]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 128, 128]             256\n",
      "             ReLU-39        [-1, 128, 128, 128]               0\n",
      "           Conv2d-40          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 64, 64]             256\n",
      "             ReLU-42          [-1, 128, 64, 64]               0\n",
      "           Conv2d-43          [-1, 512, 64, 64]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 64, 64]           1,024\n",
      "           Conv2d-45          [-1, 512, 64, 64]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-47          [-1, 512, 64, 64]               0\n",
      "       Bottleneck-48          [-1, 512, 64, 64]               0\n",
      "           Conv2d-49          [-1, 128, 64, 64]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 64, 64]             256\n",
      "             ReLU-51          [-1, 128, 64, 64]               0\n",
      "           Conv2d-52          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 64, 64]             256\n",
      "             ReLU-54          [-1, 128, 64, 64]               0\n",
      "           Conv2d-55          [-1, 512, 64, 64]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-57          [-1, 512, 64, 64]               0\n",
      "       Bottleneck-58          [-1, 512, 64, 64]               0\n",
      "           Conv2d-59          [-1, 128, 64, 64]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 64, 64]             256\n",
      "             ReLU-61          [-1, 128, 64, 64]               0\n",
      "           Conv2d-62          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 64, 64]             256\n",
      "             ReLU-64          [-1, 128, 64, 64]               0\n",
      "           Conv2d-65          [-1, 512, 64, 64]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-67          [-1, 512, 64, 64]               0\n",
      "       Bottleneck-68          [-1, 512, 64, 64]               0\n",
      "           Conv2d-69          [-1, 128, 64, 64]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 64, 64]             256\n",
      "             ReLU-71          [-1, 128, 64, 64]               0\n",
      "           Conv2d-72          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 64, 64]             256\n",
      "             ReLU-74          [-1, 128, 64, 64]               0\n",
      "           Conv2d-75          [-1, 512, 64, 64]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-77          [-1, 512, 64, 64]               0\n",
      "       Bottleneck-78          [-1, 512, 64, 64]               0\n",
      "           Conv2d-79          [-1, 256, 64, 64]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 64, 64]             512\n",
      "             ReLU-81          [-1, 256, 64, 64]               0\n",
      "           Conv2d-82          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 32, 32]             512\n",
      "             ReLU-84          [-1, 256, 32, 32]               0\n",
      "           Conv2d-85         [-1, 1024, 32, 32]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 32, 32]           2,048\n",
      "           Conv2d-87         [-1, 1024, 32, 32]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-89         [-1, 1024, 32, 32]               0\n",
      "       Bottleneck-90         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-91          [-1, 256, 32, 32]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 32, 32]             512\n",
      "             ReLU-93          [-1, 256, 32, 32]               0\n",
      "           Conv2d-94          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 32, 32]             512\n",
      "             ReLU-96          [-1, 256, 32, 32]               0\n",
      "           Conv2d-97         [-1, 1024, 32, 32]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-99         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-100         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-101          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 32, 32]             512\n",
      "            ReLU-103          [-1, 256, 32, 32]               0\n",
      "          Conv2d-104          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 32, 32]             512\n",
      "            ReLU-106          [-1, 256, 32, 32]               0\n",
      "          Conv2d-107         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-109         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-110         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-111          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 32, 32]             512\n",
      "            ReLU-113          [-1, 256, 32, 32]               0\n",
      "          Conv2d-114          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 32, 32]             512\n",
      "            ReLU-116          [-1, 256, 32, 32]               0\n",
      "          Conv2d-117         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-119         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-120         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-121          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 32, 32]             512\n",
      "            ReLU-123          [-1, 256, 32, 32]               0\n",
      "          Conv2d-124          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 32, 32]             512\n",
      "            ReLU-126          [-1, 256, 32, 32]               0\n",
      "          Conv2d-127         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-129         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-130         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-131          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 32, 32]             512\n",
      "            ReLU-133          [-1, 256, 32, 32]               0\n",
      "          Conv2d-134          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 32, 32]             512\n",
      "            ReLU-136          [-1, 256, 32, 32]               0\n",
      "          Conv2d-137         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-139         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-140         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-141          [-1, 512, 32, 32]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-143          [-1, 512, 32, 32]               0\n",
      "          Conv2d-144          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-146          [-1, 512, 16, 16]               0\n",
      "          Conv2d-147         [-1, 2048, 16, 16]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 16, 16]           4,096\n",
      "          Conv2d-149         [-1, 2048, 16, 16]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-151         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-152         [-1, 2048, 16, 16]               0\n",
      "          Conv2d-153          [-1, 512, 16, 16]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-155          [-1, 512, 16, 16]               0\n",
      "          Conv2d-156          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-158          [-1, 512, 16, 16]               0\n",
      "          Conv2d-159         [-1, 2048, 16, 16]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-161         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-162         [-1, 2048, 16, 16]               0\n",
      "          Conv2d-163          [-1, 512, 16, 16]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-165          [-1, 512, 16, 16]               0\n",
      "          Conv2d-166          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-168          [-1, 512, 16, 16]               0\n",
      "          Conv2d-169         [-1, 2048, 16, 16]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-171         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-172         [-1, 2048, 16, 16]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                  [-1, 256]         524,544\n",
      "       LeakyReLU-175                  [-1, 256]               0\n",
      "          Linear-176                  [-1, 128]          32,896\n",
      "       LeakyReLU-177                  [-1, 128]               0\n",
      "          Linear-178                    [-1, 1]             129\n",
      "         Sigmoid-179                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 24,065,601\n",
      "Trainable params: 24,065,601\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 1497.02\n",
      "Params size (MB): 91.80\n",
      "Estimated Total Size (MB): 1591.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(resnet50, input_size = (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5666dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the first layer\n",
    "\n",
    "for w in resnet50.parameters():\n",
    "    w = w.data.cpu()\n",
    "    print(w.shape)\n",
    "    break\n",
    "    \n",
    "#weight renormalization\n",
    "min_w = torch.min(w)\n",
    "w1 = (-1 / (2*min_w)) *w + 0.5\n",
    "\n",
    "# make grid\n",
    "grid_size = len(w1)\n",
    "x_grid = [w1[i] for i in range(grid_size)]\n",
    "x_grid = torchvision.utils.make_grid(x_grid, nrow = 8, padding=1)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "imshow(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e3d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장 함수\n",
    "\n",
    "def save_model(model, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok = True)\n",
    "    check_point = {\n",
    "        'net': model.state_dict(),\n",
    "    }\n",
    "    output_path = os.path.join(save_dir)\n",
    "    torch.save(check_point, save_dir+'/best_model_weight.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94365a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model train\n",
    "class Config:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cd3c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class train_test():\n",
    "    def __init__(self, config):\n",
    "        self.trainloader = config.trainloader\n",
    "        self.testloader = config.testloader\n",
    "        self.model = config.model\n",
    "        self.device = config.device\n",
    "        self.optimizer = config.optimizer\n",
    "        self.criterion = config.criterion\n",
    "        self.globaliter = config.globaliter\n",
    "        print('trainloader:', len(self.trainloader))\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        best_score =0\n",
    "        best_model = None\n",
    "        for epoch in range(1, epochs+1):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader):\n",
    "                self.globaliter +=1\n",
    "                threshold = 0.5\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                outputs = outputs.squeeze(1).to(device)\n",
    "\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            print(f'train epoch {epoch} is done')\n",
    "                     \n",
    "            with torch.no_grad(): #validation\n",
    "                self.model.eval()\n",
    "                test_loss =[]\n",
    "                f1_score =[]\n",
    "                threshold = 0.\n",
    "                for k, data in enumerate(self.testloader, 0):\n",
    "                    images, label = data\n",
    "                    images = images.to(self.device)\n",
    "                    labels = label.to(self.device)\n",
    "                    print( 'target:', label, type(label), labels)\n",
    "                    test_outputs = self.model(images)\n",
    "                    test_outputs = test_outputs.squeeze(1).to(device)\n",
    "                    \n",
    "                    #_, predicted = torch.max(outputs.data, 1)\n",
    "                    # total += labels.size(0)\n",
    "                    # correct += (predicted == labels).sum().item()\n",
    "                    print('pred_labels',test_outputs, type(test_outputs))\n",
    "                    test_loss.append(self.criterion(test_outputs, labels.float()))\n",
    "                    pred_labels = np.where(np.array(test_outputs) > threshold, 1, 0)\n",
    "                    score = metrics.f1_score(y_true=labels, y_pred=pred_labels, average='macro')\n",
    "                    f1_score.append(score)\n",
    "                print(f'Epoch [{epoch}], Train Loss : [{loss:.5f}] Val Loss : [{np.mean(test_loss):.5f}] f1 Score : [{np.mean(f1_score):.5f}]')\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                best_model = self.model\n",
    "                save_model(best_model, './models')\n",
    "            print(f'epoch {epoch} is saved')\n",
    "        return best_model\n",
    "                    \n",
    "        print('train finished')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b7bfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "\n",
    "config = Config(\n",
    "    trainloader = albumentations_train_loader,\n",
    "    testloader = albumentations_test_loader,\n",
    "    model = resnet50, \n",
    "    device = device, \n",
    "    \n",
    "    optimizer = torch.optim.Adam(resnet50.parameters(), lr = lr),\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device), #CrossEntropyLoss().to(device),\n",
    "    globaliter=0\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b50e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader: 57\n"
     ]
    }
   ],
   "source": [
    "ready_to_train=train_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24e346c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 1 is done\n",
      "target: tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]) <class 'torch.Tensor'> tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1])\n",
      "pred_labels tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "target: tensor([1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1]) <class 'torch.Tensor'> tensor([1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "pred_labels tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "target: tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]) <class 'torch.Tensor'> tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "pred_labels tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "target: tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0]) <class 'torch.Tensor'> tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0])\n",
      "pred_labels tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "target: tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0]) <class 'torch.Tensor'> tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0])\n",
      "pred_labels tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "target: tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0]) <class 'torch.Tensor'> tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "pred_labels tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "target: tensor([0, 1, 0, 1]) <class 'torch.Tensor'> tensor([0, 1, 0, 1])\n",
      "pred_labels tensor([0., 0., 0., 0.]) <class 'torch.Tensor'>\n",
      "Epoch [1], Train Loss : [0.69315] Val Loss : [0.69315] f1 Score : [0.29432]\n",
      "epoch 1 is saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lr_sche \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(config\u001b[38;5;241m.\u001b[39moptimizer, T_max \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model_done\u001b[38;5;241m=\u001b[39m \u001b[43mready_to_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mtrain_test.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 33\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_sche = optim.lr_scheduler.CosineAnnealingLR(config.optimizer, T_max =20) \n",
    "epochs = 20\n",
    "\n",
    "\n",
    "model_done= ready_to_train.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83e331",
   "metadata": {},
   "source": [
    "model based on https://github.com/inhovation97/Image_classification_pipeline_Project/blob/main/pytorch/pytorch_project_fine_tuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65944024",
   "metadata": {},
   "outputs": [],
   "source": [
    "## submission\n",
    "test_csv = pd.read_csv('./test.csv')\n",
    "test_dataset = inhovation_Dataset(test_csv, None, transform = albumentations_test)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ce595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            img = img.float().to(device)\n",
    "            \n",
    "            model_pred = model(im)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            \n",
    "            preds += model_pred.tolist()\n",
    "    \n",
    "    preds = np.where(np.array(preds) > threshold, 1, 0)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(infer_model, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(infer_model, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd94abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['N_category'] = preds\n",
    "submit.to_csv('./submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db3abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3269ae4c9c0482ebadb7d2cefd5ce507b8dd1bbb443fca54db5d14384d2c55eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
