{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1170e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f4e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/krc/Documents/breast_dacon/dacon_bc_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88c50772",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') if torch.backends.mps.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede017cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/krc/Documents/breast_dacon'\n",
    "\n",
    "train_df = pd.read_csv('/Users/krc/Documents/breast_dacon/open/train.csv')\n",
    "test_df = pd.read_csv('/Users/krc/Documents/breast_dacon/open/test.csv')\n",
    "\n",
    "# os.mkdir('./new_train') \n",
    "# os.mkdir('./new_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706a277",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## resize (background delete) - K means - score evaluation - apply crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d9caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/krc/Documents/breast_dacon/dacon_bc_prediction'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67aa31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "import copy \n",
    "\n",
    "#From t.ly/TLq_\n",
    "\n",
    "\n",
    "class KMeans():\n",
    "    def __init__(self, n_clusters, max_iter = 20, random_state = 60):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def initialize_centroids(self, X): # center 초기화 - 이미지 내 특정 점으로 고정\n",
    "        np.random.RandomState(self.random_state)\n",
    "        random_idx = np.random.permutation(X.shape[0])\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "\n",
    "        return centroids\n",
    "        \n",
    "    def compute_centroids(self, X, labels): # centroids 계산 \n",
    "        centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "        \n",
    "    def compute_distance(self, X, centroids): #\n",
    "        distance = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            row_norm = norm(X - centroids[k, :], axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "    \n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "    \n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(X.shape[0])\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.centroids = self.initialize_centroids(X)\n",
    " \n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "        # return self.labels\n",
    "        \n",
    "    def predict(self, X):\n",
    "        distance = self.compute_distance(X, self.centroids)\n",
    "        return self.find_closest_cluster(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2546d677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 is starting.. \n",
      "BC_01_1092.png has one image\n",
      "index 20 is starting.. \n",
      "index 40 is starting.. \n",
      "index 60 is starting.. \n",
      "BC_01_1939.png has one image\n",
      "BC_01_1093.png has one image\n",
      "BC_01_1091.png has one image\n",
      "index 80 is starting.. \n",
      "index 100 is starting.. \n",
      "BC_01_2348.png has one image\n",
      "BC_01_0007.png has one image\n",
      "index 120 is starting.. \n",
      "index 140 is starting.. \n",
      "index 160 is starting.. \n",
      "BC_01_0215.png has one image\n",
      "BC_01_2358.png has one image\n",
      "BC_01_0214.png has one image\n",
      "index 180 is starting.. \n",
      "BC_01_0348.png has one image\n",
      "BC_01_2575.png has one image\n",
      "index 200 is starting.. \n",
      "index 220 is starting.. \n",
      "BC_01_0217.png has one image\n",
      "index 240 is starting.. \n",
      "BC_01_0304.png has one image\n",
      "index 260 is starting.. \n",
      "BC_01_0674.png has one image\n",
      "BC_01_1436.png has one image\n",
      "BC_01_2659.png has one image\n",
      "index 280 is starting.. \n",
      "index 300 is starting.. \n",
      "BC_01_1345.png has one image\n",
      "index 320 is starting.. \n",
      "BC_01_1582.png has one image\n",
      "index 340 is starting.. \n",
      "BC_01_0298.png has one image\n",
      "index 360 is starting.. \n",
      "BC_01_2288.png has one image\n",
      "BC_01_0302.png has one image\n",
      "BC_01_2267.png has one image\n",
      "index 380 is starting.. \n",
      "index 400 is starting.. \n",
      "index 420 is starting.. \n",
      "index 440 is starting.. \n",
      "index 460 is starting.. \n",
      "index 480 is starting.. \n",
      "BC_01_0880.png has one image\n",
      "index 500 is starting.. \n",
      "BC_01_2877.png has one image\n",
      "index 520 is starting.. \n",
      "BC_01_2334.png has one image\n",
      "index 540 is starting.. \n",
      "index 560 is starting.. \n",
      "index 580 is starting.. \n",
      "BC_01_0246.png has one image\n",
      "BC_01_1831.png has one image\n",
      "BC_01_0285.png has one image\n",
      "BC_01_0284.png has one image\n",
      "index 600 is starting.. \n",
      "index 620 is starting.. \n",
      "BC_01_2050.png has one image\n",
      "index 640 is starting.. \n",
      "BC_01_2332.png has one image\n",
      "BC_01_2327.png has one image\n",
      "index 660 is starting.. \n",
      "BC_01_0875.png has one image\n",
      "index 680 is starting.. \n",
      "BC_01_1982.png has one image\n",
      "BC_01_0491.png has one image\n",
      "index 700 is starting.. \n",
      "BC_01_2325.png has one image\n",
      "BC_01_0268.png has one image\n",
      "BC_01_1611.png has one image\n",
      "index 720 is starting.. \n",
      "BC_01_0862.png has one image\n",
      "index 740 is starting.. \n",
      "index 760 is starting.. \n",
      "BC_01_1676.png has one image\n",
      "index 780 is starting.. \n",
      "BC_01_2801.png has one image\n",
      "BC_01_1298.png has one image\n",
      "index 800 is starting.. \n",
      "index 820 is starting.. \n",
      "BC_01_2977.png has one image\n",
      "BC_01_0966.png has one image\n",
      "index 840 is starting.. \n",
      "BC_01_2143.png has one image\n",
      "index 860 is starting.. \n",
      "BC_01_2779.png has one image\n",
      "BC_01_1927.png has one image\n",
      "index 880 is starting.. \n",
      "index 900 is starting.. \n",
      "BC_01_2436.png has one image\n",
      "index 920 is starting.. \n",
      "BC_01_2024.png has one image\n",
      "BC_01_1539.png has one image\n",
      "index 940 is starting.. \n",
      "BC_01_2959.png has one image\n",
      "BC_01_0223.png has one image\n",
      "index 960 is starting.. \n",
      "BC_01_2390.png has one image\n",
      "index 980 is starting.. \n",
      "BC_01_0342.png has one image\n"
     ]
    }
   ],
   "source": [
    "# file_path = '/Users/krc/Documents/breast_dacon/train_imgs/'\n",
    "# file_list = os.walk(file_path)  # OS로 불러오기\n",
    "# img_files = [file for file in file_list if file[-1][-1].endswith(\".png\")]\n",
    "\n",
    "\n",
    "\n",
    "# if not img_files:  # if empty folder\n",
    "#     print(\"there are no png files\")\n",
    "#     sys.exit()\n",
    "\n",
    "# for i, f in enumerate(img_files[0][2]):\n",
    "#     if i% 20 == 0:\n",
    "#         print(f'index {i} is starting.. ')\n",
    "#     # t.ly/zgLP\n",
    "#     image = cv2.imread(file_path + f)\n",
    "#     y_orig, x_orig, channel= image.shape\n",
    "#     if x_orig / y_orig < 1.5:\n",
    "#         cv2.imwrite(f'./new_train/{f}', image)\n",
    "#         print(f'{f} has one image')\n",
    "#         continue\n",
    "#     gray_sample = image.copy()\n",
    "#     gray_sample = cv2.cvtColor(gray_sample, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "#     # 모양 맞추기 flip \n",
    "#     gray_sample =cv2.flip(gray_sample, 0)\n",
    "#     # resize to 400 * 200\n",
    "#     gray_sample = cv2.resize(gray_sample, dsize=(400, 200), interpolation=cv2.INTER_LINEAR) \n",
    "    \n",
    "#     #전처리\n",
    "#     coord = np.where( gray_sample < 239 )\n",
    "#     co_array = np.array(coord)\n",
    "#     co_array = np.float32(co_array).T\n",
    "#     from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "#     best_score = 0\n",
    "#     best_k = 1\n",
    "#     best_centroids = []\n",
    "\n",
    "#     for j, k in enumerate([ 4, 3, 2]):\n",
    "        \n",
    "#         # Run the Kmeans algorithm\n",
    "#         km = KMeans(n_clusters=k)\n",
    "#         km.fit(co_array)\n",
    "#         labels = km.predict(co_array) # input data\n",
    "\n",
    "#         centroids = km.compute_centroids(co_array, labels) # cluster_centers_\n",
    "#         # Get silhouette samples\n",
    "#         silhouette_vals = silhouette_samples(co_array, labels)\n",
    "\n",
    "#         # Get the average silhouette score and plot it\n",
    "#         avg_score = np.mean(silhouette_vals) ## score \n",
    "\n",
    "#         # print('K = ',k, 'avg_score:', avg_score)\n",
    "\n",
    "#         if best_score < avg_score:\n",
    "#             if best_k == 3 and k ==2 and (avg_score-best_score) < 0.09:\n",
    "#                 break\n",
    "#             best_score = avg_score\n",
    "#             best_k = k\n",
    "#             best_centroids = centroids\n",
    "#             x_coord = centroids[ : , 1]\n",
    "#             x_coord.sort()        \n",
    "#             if best_k == 2:\n",
    "#                 x1, x2 = x_coord\n",
    "#             elif best_k ==3  :\n",
    "#                 x1, x2, x3 = x_coord\n",
    "#             elif best_k ==4  :\n",
    "#                 x1, x2, x3, x4 = x_coord\n",
    "\n",
    "#     if best_k == 2:\n",
    "#         crop_image = image[:, : int( (x1+x2)/2  *x_orig / 400 ), :]\n",
    "#     elif best_k > 2:\n",
    "#         alpha = int(y_orig / 2)\n",
    "#         crop_image = image[:, max(0, int(x2 *x_orig /400) -alpha)  :int(x2 *x_orig /400) +alpha , : ] ## 마이너스나옴 \n",
    "\n",
    "#     cv2.imwrite(f'./new_train/{f}', crop_image)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "256b5fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 is starting.. \n",
      "image BC_01_3257.png has one image\n",
      "image BC_01_1246.png has one image\n",
      "index 20 is starting.. \n",
      "image BC_01_2774.png has one image\n",
      "image BC_01_2629.png has one image\n",
      "index 40 is starting.. \n",
      "image BC_01_0933.png has one image\n",
      "index 60 is starting.. \n",
      "image BC_01_2263.png has one image\n",
      "index 80 is starting.. \n",
      "index 100 is starting.. \n",
      "image BC_01_2933.png has one image\n",
      "image BC_01_2718.png has one image\n",
      "index 120 is starting.. \n",
      "image BC_01_2527.png has one image\n",
      "index 140 is starting.. \n",
      "image BC_01_0848.png has one image\n",
      "index 160 is starting.. \n",
      "image BC_01_0526.png has one image\n",
      "index 180 is starting.. \n",
      "image BC_01_0233.png has one image\n",
      "image BC_01_0390.png has one image\n",
      "index 200 is starting.. \n",
      "image BC_01_2803.png has one image\n",
      "index 220 is starting.. \n",
      "index 240 is starting.. \n"
     ]
    }
   ],
   "source": [
    "# # test imgs crop \n",
    "# file_path = '/Users/krc/Documents/breast_dacon/test_imgs/'\n",
    "# file_list = os.walk(file_path)  # OS로 불러오기\n",
    "# img_files = [file for file in file_list if file[-1][-1].endswith(\".png\")]\n",
    "\n",
    "\n",
    "\n",
    "# if not img_files:  # if empty folder\n",
    "#     print(\"there are no png files\")\n",
    "#     sys.exit()\n",
    "\n",
    "# for i, f in enumerate(img_files[0][2]):\n",
    "#     if i% 20 == 0:\n",
    "#         print(f'index {i} is starting.. ')\n",
    "#     # t.ly/zgLP\n",
    "#     image = cv2.imread(file_path + f)\n",
    "#     y_orig, x_orig, channel= image.shape\n",
    "#     if x_orig / y_orig < 1.5:\n",
    "#         cv2.imwrite(f'./new_test/{f}', image)\n",
    "#         print(f'image {f} has one image')\n",
    "#         continue\n",
    "#     gray_sample = image.copy()\n",
    "#     gray_sample = cv2.cvtColor(gray_sample, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "#     # 모양 맞추기 flip \n",
    "#     gray_sample =cv2.flip(gray_sample, 0)\n",
    "#     # resize to 400 * 200\n",
    "#     gray_sample = cv2.resize(gray_sample, dsize=(400, 200), interpolation=cv2.INTER_LINEAR) \n",
    "    \n",
    "#     #전처리\n",
    "#     coord = np.where( gray_sample < 239 )\n",
    "#     co_array = np.array(coord)\n",
    "#     co_array = np.float32(co_array).T\n",
    "#     from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "#     best_score = 0\n",
    "#     best_k = 1\n",
    "#     best_centroids = []\n",
    "\n",
    "#     for j, k in enumerate([ 4, 3, 2]):\n",
    "        \n",
    "#         # Run the Kmeans algorithm\n",
    "#         km = KMeans(n_clusters=k)\n",
    "#         km.fit(co_array)\n",
    "#         labels = km.predict(co_array) # input data\n",
    "\n",
    "#         centroids = km.compute_centroids(co_array, labels) # cluster_centers_\n",
    "#         # Get silhouette samples\n",
    "#         silhouette_vals = silhouette_samples(co_array, labels)\n",
    "\n",
    "#         # Get the average silhouette score and plot it\n",
    "#         avg_score = np.mean(silhouette_vals) ## score \n",
    "\n",
    "#         # print('K = ',k, 'avg_score:', avg_score)\n",
    "\n",
    "#         if best_score < avg_score:\n",
    "#             if best_k == 3 and k ==2 and (avg_score-best_score) < 0.09:\n",
    "#                 break\n",
    "#             best_score = avg_score\n",
    "#             best_k = k\n",
    "#             best_centroids = centroids\n",
    "#             x_coord = centroids[ : , 1]\n",
    "#             x_coord.sort()        \n",
    "#             if best_k == 2:\n",
    "#                 x1, x2 = x_coord\n",
    "#             elif best_k ==3  :\n",
    "#                 x1, x2, x3 = x_coord\n",
    "#             elif best_k ==4  :\n",
    "#                 x1, x2, x3, x4 = x_coord\n",
    "\n",
    "#     if best_k == 2:\n",
    "#         crop_image = image[:, : int( (x1+x2)/2  *x_orig / 400 ), :]\n",
    "#     elif best_k > 2:\n",
    "#         alpha = int(y_orig / 2)\n",
    "#         crop_image = image[:, max(0, int(x2 *x_orig /400) -alpha)  :int(x2 *x_orig /400) +alpha , : ] ## 마이너스나옴 \n",
    "\n",
    "#     cv2.imwrite(f'./new_test/{f}', crop_image)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216f0ab",
   "metadata": {},
   "source": [
    "--- \n",
    "## Model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae259f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypter parameter\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE':1024,\n",
    "    'IMG_SIZE_D':1024,\n",
    "    'EPOCHS':20,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efff6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "    torch.backends.mps.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae8408",
   "metadata": {},
   "source": [
    "### data load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6cf44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('../open/train.csv')\n",
    "test_df = pd.read_csv('../open/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16cb23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, train_labels, val_labels = train_test_split(\n",
    "                                                    train_df.drop(columns=['N_category']), \n",
    "                                                    train_df['N_category'], \n",
    "                                                    test_size=0.1,  # 0.2 \n",
    "                                                    random_state=CFG['SEED']\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0deb101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './new_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78daf768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./new_test/BC_01_2318.png'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base + train_df['img_path'].iloc[0][-14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac860ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, medical_df, labels, transforms=None):\n",
    "        self.medical_df = medical_df\n",
    "        self.transforms = transforms\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = base + self.medical_df['img_path'].iloc[index][-14:]\n",
    "        # print(img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "                \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image,  label #tabular = 2nd\n",
    "        else:\n",
    "            return image #, tabular\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.medical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e4d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "                            A.HorizontalFlip(),\n",
    "                            A.VerticalFlip(),\n",
    "                            A.Rotate(limit=180, border_mode=cv2.BORDER_CONSTANT,p=0.3),\n",
    "                            A.GaussNoise(p=0.2), #NOISE ADD \n",
    "                            A.Resize(CFG['IMG_SIZE_D'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE_D'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35114ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, train_labels.values, train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_df, val_labels.values, test_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f3927",
   "metadata": {},
   "source": [
    "## model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047fcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImgFeatureExtractor, self).__init__()\n",
    "        self.backbone = models.swin_s(weights=True)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.backbone.head.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.embedding = nn.Linear(1000,512)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f48c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.img_feature_extractor = ImgFeatureExtractor()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(in_features=64, out_features=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, img): \n",
    "        img_feature = self.img_feature_extractor(img)\n",
    "        output = self.classifier(img_feature) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c50857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_epcoh = 0 \n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for img, label in tqdm(iter(train_loader)): \n",
    "            img = img.float().to(device)\n",
    "            label = label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            \n",
    "            loss = criterion(model_pred, label.reshape(-1,1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss, val_score = validation(model, criterion, val_loader, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}] Val Score : [{val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "        \n",
    "        if best_score < val_score:\n",
    "            best_epoch = epoch\n",
    "            best_score = val_score\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), f'./{epoch}_model.pth')\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "579188d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    val_loss = []\n",
    "    threshold = 0.5\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(val_loader)): \n",
    "            true_labels += label.tolist()\n",
    "            \n",
    "            img = img.float().to(device)\n",
    "            label = label.float().to(device)\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            \n",
    "            loss = criterion(model_pred, label.reshape(-1,1))\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')  \n",
    "            pred_labels += model_pred.tolist()\n",
    "    \n",
    "    pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "    val_score = metrics.f1_score(y_true=true_labels, y_pred=pred_labels, average='macro')\n",
    "    return np.mean(val_loss), val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb9f90fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7756fd800b944d0ebb67e229c156b831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f985fe5d4f0e474bb7995784c021bf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.69816] Val Loss : [0.68247] Val Score : [0.27536]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8a872fc2e449b9868eab4b8a224ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb9e126ea5f40289dc01f1eeed8509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.68059] Val Loss : [0.63513] Val Score : [0.51240]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e75a7381b6d4a39821acc1017ed4d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d614c53c2c90474faaaf1326addeac08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.66264] Val Loss : [0.60371] Val Score : [0.63986]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c7f2e13aa345b4b0db9258a2b35d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9390fd02bd9545c48c5c1be9cecab801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.64995] Val Loss : [0.60523] Val Score : [0.63870]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c0e824ea10442bb08111905c103f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a469f3d00ff14828bfffb2b453f2ce9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.64508] Val Loss : [0.61122] Val Score : [0.60682]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c24dc194cc64145b6ac1cf1b046ce30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f51f9e067384c3187d44680bc6c6037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.64180] Val Loss : [0.58031] Val Score : [0.72780]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fa2af777d644df9ef6729baf085ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0ad4cee6924280b2bf9f69bd2b42fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.64211] Val Loss : [0.59177] Val Score : [0.68922]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9263d736d1454a0ebf317a843a484746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17e70d9b4a3411eb43d9712de2b36b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.64355] Val Loss : [0.58100] Val Score : [0.71820]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad91fe4c5d844edfa5f2b294cf878caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a1e01783cf4a1fbfc68c8f7067227c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.64586] Val Loss : [0.59613] Val Score : [0.64968]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c05efcce424b9da4a44f3df37faa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2b8fb6ca9046f79cf15afa2e894a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.63818] Val Loss : [0.58540] Val Score : [0.71717]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7533fabbcde402bb8688fd07514120f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969ef564ada14606b7e9a270a81a9fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.63210] Val Loss : [0.58244] Val Score : [0.71717]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b845b2855e47a58e74963102d07e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5d465aff1f47e0b806d794527aa238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.63478] Val Loss : [0.58395] Val Score : [0.69697]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8ae62db7d946119a35e03b60954ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91bf57c96e74c55b1e1ee6fb78d5494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.63846] Val Loss : [0.60473] Val Score : [0.64968]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed9981c751b40ffa6904d4d4167efb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab9761924d14bb6943240557eb7292c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.63552] Val Loss : [0.59417] Val Score : [0.68997]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d97d577530748f89a426fcfc85bdafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e297abf907204e6092c5b74af6afff2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.63705] Val Loss : [0.58932] Val Score : [0.71899]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9270e04beed04713b930ceb0806a596c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170fd2608fe04a2da918411fd90845f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.63607] Val Loss : [0.59419] Val Score : [0.69988]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45b8979a70a4d68ade3d35c3c0a65dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1d11a545b449eeb724201375cbd2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.62968] Val Loss : [0.59983] Val Score : [0.64968]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469d01cff7d0448a85f1b6828465cd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4c04c09a6c48eda8ae1b6bce012317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.63611] Val Loss : [0.60441] Val Score : [0.65986]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87c0404868d4969b5f612efa39d3761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f33242ed304692ac7bab028060c4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.63013] Val Loss : [0.60187] Val Score : [0.64996]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb66ae60a90340e3a5a4c867506491a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f71d6d53964840a6f7aa0c1974b7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.63100] Val Loss : [0.60139] Val Score : [0.66000]\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(ClassificationModel())\n",
    "\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "scheduler = None\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd80c6",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f84da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14f62d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './new_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b98a8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df, None, test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ebf587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    #model.to(device)\n",
    "#     model.eval()\n",
    "    preds = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)): # , tabular   = 2nd\n",
    "            img = img.float().to(device)\n",
    "            # tabular = tabular.float().to(device)\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            \n",
    "            preds += model_pred.tolist()\n",
    "    \n",
    "    preds = np.where(np.array(preds) > threshold, 1, 0)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d79b5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11f794ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18ff329ae3a47358f35cefc4becaaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "193b84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['N_category'] = preds\n",
    "submit.to_csv('./submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643aeefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
